{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('reviews.txt','r')\n",
    "reviews = list(map(lambda x:x[:],g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('labels.txt','r') \n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reviews=reviews[:-1000]\n",
    "labels=labels[:-1000]\n",
    "min_count=20\n",
    "polarity_cutoff=0.1\n",
    "learning_rate=0.01\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "                positive_counts[word] += 1\n",
    "                total_counts[word] += 1\n",
    "    else:\n",
    "         for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "\n",
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt >= 50):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6320"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_neg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vocab = set()\n",
    "for review in reviews:\n",
    "    for word in review.split(\" \"):\n",
    "        \n",
    "        if(total_counts[word] > min_count):\n",
    "            if(word in pos_neg_ratios.keys()):\n",
    "                if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                    review_vocab.add(word)\n",
    "            #else:\n",
    "             #   review_vocab.add(word)\n",
    "\n",
    "\n",
    "review_vocab = list(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5720"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_vocab = set()\n",
    "for label in labels:\n",
    "    label_vocab.add(label)\n",
    "\n",
    "\n",
    "label_vocab = list(label_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_vocab_size = len(review_vocab)\n",
    "label_vocab_size = len(label_vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(review_vocab):\n",
    "    word2index[word] = i\n",
    "\n",
    "\n",
    "label2index = {}\n",
    "for i, label in enumerate(label_vocab):\n",
    "    label2index[label] = i\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2index['NEGATIVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_reviews = list()\n",
    "for review in reviews:\n",
    "    indices = set()\n",
    "    for word in review.split(\" \"):\n",
    "        if(word in word2index.keys()):\n",
    "            indices.add(word2index[word])\n",
    "    \n",
    "    training_reviews.append(list(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert(len(training_reviews) == len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=review_vocab_size)\n",
    "\n",
    "x_train = tokenizer.sequences_to_matrix(training_reviews, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=list()\n",
    "for i in labels:\n",
    "    y_train.append(label2index[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train[3])\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               2929152   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 2,930,178\n",
      "Trainable params: 2,930,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=review_vocab_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews=reviews[-1000:]\n",
    "test_labels=labels[-1000:]\n",
    "\n",
    "test_re = list()\n",
    "for review in test_reviews:\n",
    "    indices = set()\n",
    "    for word in review.split(\" \"):\n",
    "        if(word in word2index.keys()):\n",
    "            indices.add(word2index[word])\n",
    "    \n",
    "    test_re.append(list(indices))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.sequences_to_matrix(test_re, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=list()\n",
    "for i in test_labels:\n",
    "    y_test.append(label2index[i])\n",
    "        \n",
    "\n",
    "y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " - 28s - loss: 0.3273 - acc: 0.8618 - val_loss: 0.1731 - val_acc: 0.9425\n",
      "Epoch 2/10\n",
      " - 26s - loss: 0.1997 - acc: 0.9209 - val_loss: 0.1107 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      " - 26s - loss: 0.1261 - acc: 0.9541 - val_loss: 0.0522 - val_acc: 0.9855\n",
      "Epoch 4/10\n",
      " - 26s - loss: 0.0637 - acc: 0.9812 - val_loss: 0.0226 - val_acc: 0.9990\n",
      "Epoch 5/10\n",
      " - 26s - loss: 0.0266 - acc: 0.9940 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 26s - loss: 0.0114 - acc: 0.9981 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 26s - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 26s - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 26s - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 27s - loss: 0.0062 - acc: 0.9986 - val_loss: 9.4744e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Running and evaluating the model\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test), \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 161us/step\n",
      "\n",
      "Accuracy:  1.0\n",
      "\n",
      "Predictions:\n",
      "[[9.9941492e-01 6.0479558e-04]\n",
      " [1.2546689e-04 9.9988186e-01]\n",
      " [9.9997473e-01 2.5468176e-05]\n",
      " ...\n",
      " [2.0578027e-07 9.9999976e-01]\n",
      " [9.9810874e-01 1.7739226e-03]\n",
      " [7.8516248e-05 9.9992967e-01]]\n"
     ]
    }
   ],
   "source": [
    "        score = model.evaluate(x_test, y_test)\n",
    "        print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "        print(\"\\nPredictions:\")\n",
    "        print(model.predict_proba(x_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsao(review):\n",
    "    teste= review\n",
    "    rev=set()\n",
    "    \n",
    "    for word in teste.split(' '):\n",
    "        if(word in word2index.keys()):\n",
    "            rev.add(word2index[word])\n",
    "    x_1=list()\n",
    "    x_1.append(list(rev))\n",
    "\n",
    "\n",
    "    x = tokenizer.sequences_to_matrix(x_1, mode='binary')\n",
    "\n",
    "\n",
    "    prediction=model.predict(x)\n",
    "\n",
    "    if(prediction[0][0]>prediction[0][1]):\n",
    "        print('POSITIVE')\n",
    "    else:\n",
    "        print('NEGATIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "previsao('this movie is awesome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
