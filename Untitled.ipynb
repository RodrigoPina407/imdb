{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('reviews.txt','r')\n",
    "reviews = list(map(lambda x:x[:],g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('labels.txt','r') \n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reviews=reviews[:-1000]\n",
    "labels=labels[:-1000]\n",
    "min_count=20\n",
    "polarity_cutoff=0.05\n",
    "learning_rate=0.01\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "                positive_counts[word] += 1\n",
    "                total_counts[word] += 1\n",
    "    else:\n",
    "         for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "\n",
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt >= 50):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6991"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_neg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vocab = set()\n",
    "for review in reviews:\n",
    "    for word in review.split(\" \"):\n",
    "        \n",
    "        if(total_counts[word] > min_count):\n",
    "            if(word in pos_neg_ratios.keys()):\n",
    "                if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                    review_vocab.add(word)\n",
    "                else:\n",
    "                    review_vocab.add(word)\n",
    "\n",
    "\n",
    "review_vocab = list(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6991"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_vocab = set()\n",
    "for label in labels:\n",
    "    label_vocab.add(label)\n",
    "\n",
    "\n",
    "label_vocab = list(label_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_vocab_size = len(review_vocab)\n",
    "label_vocab_size = len(label_vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(review_vocab):\n",
    "    word2index[word] = i\n",
    "\n",
    "\n",
    "label2index = {}\n",
    "for i, label in enumerate(label_vocab):\n",
    "    label2index[label] = i\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_reviews = list()\n",
    "for review in reviews:\n",
    "    indices = set()\n",
    "    for word in review.split(\" \"):\n",
    "        if(word in word2index.keys()):\n",
    "            indices.add(word2index[word])\n",
    "    \n",
    "    training_reviews.append(list(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert(len(training_reviews) == len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=review_vocab_size)\n",
    "\n",
    "x_train = tokenizer.sequences_to_matrix(training_reviews, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=list()\n",
    "for i in labels:\n",
    "    y_train.append(label2index[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), 'POSITIVE')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train[3])\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               3579904   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,580,930\n",
      "Trainable params: 3,580,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=review_vocab_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews=reviews[-1000:]\n",
    "test_labels=labels[-1000:]\n",
    "\n",
    "test_re = list()\n",
    "for review in test_reviews:\n",
    "    indices = set()\n",
    "    for word in review.split(\" \"):\n",
    "        if(word in word2index.keys()):\n",
    "            indices.add(word2index[word])\n",
    "    \n",
    "    test_re.append(list(indices))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.sequences_to_matrix(test_re, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=list()\n",
    "for i in test_labels:\n",
    "    y_test.append(label2index[i])\n",
    "        \n",
    "\n",
    "y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " - 14s - loss: 0.0228 - acc: 0.9959 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.0146 - acc: 0.9981 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0103 - acc: 0.9992 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.0072 - acc: 0.9995 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 14s - loss: 0.0054 - acc: 0.9998 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.0025 - acc: 0.9999 - val_loss: 7.9820e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 14s - loss: 0.0021 - acc: 1.0000 - val_loss: 6.7989e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 15s - loss: 0.0016 - acc: 1.0000 - val_loss: 5.0166e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Running and evaluating the model\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=120,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test), \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 207us/step\n",
      "\n",
      "Accuracy:  1.0\n",
      "\n",
      "Predictions:\n",
      "[[3.9462373e-03 9.9671352e-01]\n",
      " [9.9998009e-01 2.1449019e-05]\n",
      " [3.5638233e-05 9.9993384e-01]\n",
      " ...\n",
      " [9.9995756e-01 5.3396532e-05]\n",
      " [2.9086731e-03 9.9595046e-01]\n",
      " [1.0000000e+00 2.4484756e-08]]\n"
     ]
    }
   ],
   "source": [
    "        score = model.evaluate(x_test, y_test)\n",
    "        print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "        print(\"\\nPredictions:\")\n",
    "        print(model.predict_proba(x_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsao(review):\n",
    "    teste= review\n",
    "    rev=set()\n",
    "    \n",
    "    for word in teste.split(' '):\n",
    "        if(word in word2index.keys()):\n",
    "            rev.add(word2index[word])\n",
    "    x_1=list()\n",
    "    x_1.append(list(rev))\n",
    "\n",
    "\n",
    "    x = tokenizer.sequences_to_matrix(x_1, mode='binary')\n",
    "\n",
    "\n",
    "    prediction=model.predict(x)\n",
    "    print(prediction)\n",
    "    \n",
    "    if(prediction[0][0]>prediction[0][1]):\n",
    "        print('NEGATIVE')\n",
    "    else:\n",
    "        print('POSITIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05301136 0.94816864]]\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "previsao(\"this movie is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
